[
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Day\nTime\nLocation\n\n\n\n\nLecture\nMonday\n08:15 - 09:45 am\n016b\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that there are additional lectures (see schedule at StarPlan)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-info",
    "href": "course-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "",
    "text": "Day\nTime\nLocation\n\n\n\n\nLecture\nMonday\n08:15 - 09:45 am\n016b\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that there are additional lectures (see schedule at StarPlan)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this module, students are able to: \n\nEffectively plan and execute market research projects \nConduct experiments and A/B tests \nUse predictive models and clustering methods \nUtilize modern tools and technologies for data analysis \nClearly and effectively communicate results",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#where-to-get-help",
    "href": "course-syllabus.html#where-to-get-help",
    "title": "Syllabus",
    "section": "Where to get help",
    "text": "Where to get help\n\nIf you have a question during lecture, feel free to ask it!\nOutside of class, any general questions about course content or assignments should be posted on the Moodle course forum.\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include the name of our course in the subject line.\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nThis course is mainly based on the following resources:\n√áetinkaya-Rundel, M. & Hardin, J (2023). Introduction to Modern Statistics. OpenIntro. Inc.\nJames, G., Witten, D., Hastie, T., Tibshirani, R. & Taylor, J. (2023). An Introduction to Statistical Learning with Python. New York: Springer.\nLau, S., Gonzalez, J. & Nolan, D. (2023). Learning Data Science. O‚ÄôReilly Media, Inc.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#sec-exams",
    "href": "course-syllabus.html#sec-exams",
    "title": "Syllabus",
    "section": "Exam",
    "text": "Exam\nThere will be one exam at the end of the semester.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "data-collection/scraping-environment.html",
    "href": "data-collection/scraping-environment.html",
    "title": "Scraping Environment",
    "section": "",
    "text": "The following setup provides a comprehensive approach for both Windows and Mac users to create a structured project directory, download necessary files, and set up an isolated Python environment for web scraping.\nBy following these instructions, you will have a consistent and reproducible development environment, which is crucial for academic and professional projects.",
    "crumbs": [
      "Data Collection",
      "Scraping Environment"
    ]
  },
  {
    "objectID": "data-collection/scraping-environment.html#creating-the-project-structure",
    "href": "data-collection/scraping-environment.html#creating-the-project-structure",
    "title": "Scraping Environment",
    "section": "1 Creating the Project Structure",
    "text": "1 Creating the Project Structure\n\nFor Windows Users: Open Command Prompt (you can do this by typing cmd in the Windows search bar and hitting Enter).\nFor Mac Users: Open Terminal (you can find this in the Applications folder under Utilities, or use Spotlight by pressing Cmd + Space and typing ‚ÄúTerminal‚Äù).\n\n\nCreate a new folder called market-research:\n\nmkdir market-research\n\nNavigate into the market-research folder:\n\ncd market-research\n\nCreate a subfolder called data-collection:\n\nmkdir data-collection",
    "crumbs": [
      "Data Collection",
      "Scraping Environment"
    ]
  },
  {
    "objectID": "data-collection/scraping-environment.html#downloading-the-yaml-file",
    "href": "data-collection/scraping-environment.html#downloading-the-yaml-file",
    "title": "Scraping Environment",
    "section": "2 Downloading the YAML File",
    "text": "2 Downloading the YAML File\nNavigate into the data-collection folder before using curl to download the YAML file (I assume you already are in the folder market-research). This ensures the file is saved in the right place:\ncd data-collection\n\nMac: To print the current directory path in the Terminal, you can use the command pwd (print working directory) without any arguments.\nWindows: To print the current directory path in the Windows Command Prompt, you can use the cd command without any arguments. Simply type: cd\n\nNow use the curl command to download the env-scraping.yml file:\ncurl -LJO https://raw.githubusercontent.com/kirenz/environments/main/ss2024/env-scraping.yml\n\n2.1 Understanding curl and Its Parameters\nAfter downloading the file, let‚Äôs revisit what the curl command does and its parameters, now with the context of downloading into the data-collection folder:\n\n-L: Follows any redirects which the server might send as part of the request.\n-J: Uses the header-provided filename to save the file.\n-O: Saves the file locally with the same name as the filename on the server.",
    "crumbs": [
      "Data Collection",
      "Scraping Environment"
    ]
  },
  {
    "objectID": "data-collection/scraping-environment.html#setting-up-the-anaconda-environment",
    "href": "data-collection/scraping-environment.html#setting-up-the-anaconda-environment",
    "title": "Scraping Environment",
    "section": "3 Setting Up the Anaconda Environment",
    "text": "3 Setting Up the Anaconda Environment\nImportant Note: Before proceeding with the creation of the Anaconda environment, ensure you are in the data-collection folder where the env-scraping.yml file is located. This is crucial because the conda command looks for the YAML file in your current directory.\n\n\n\n\n\n\nWindows-User\n\n\n\n\n\nOpen Anaconda Command Prompt and navigate to the subfolder data/collection:\ncd ..\\market-research\\data-collection\n\n\n\n\n\n\n\n\n\nMac-User\n\n\n\n\n\nOpen the Terminal or use the integrated Terminal in VS Code. Navigate to the subfolder data-collection:\ncd ~/market-research/data-collection\n\n\n\nCreate the Anaconda Environment:\nconda env create -f env-scraping.yml\nThis command will create a new environment named scraping and install all the dependencies listed in the YAML file.\nActivate the Environment:\nconda activate scraping\nActivating the environment will switch your current session to use the Python version and libraries specified in the environment.\n\n3.1 Understanding the YML-file in its Content\nYAML File: YAML (YAML Ain‚Äôt Markup Language) is a human-readable data serialization standard that can be used for configuration files and other forms of data that need to be stored and transmitted. In the context of Anaconda, a YAML file specifies the environment‚Äôs name, the channels to install packages from, and the list of dependencies.\nThe provided YAML file contains:\n\nname: scraping ‚Äì the environment name.\nchannels:\n\nconda-forge: a community-led collection of recipes for conda.\ndefaults: the default channel provided by Anaconda.\n\ndependencies: the packages and versions to install:\n\npython=3.11 ‚Äì Python version 3.11.\npip ‚Äì The Python package installer.\nOther packages within the pip subsection for various tasks:\n\npandas, openpyxl for data manipulation.\njupyter for running Jupyter notebooks.\naltair, matplotlib, seaborn for data visualization.\nrequests, tweepy, beautifulsoup4 for web scraping.\nautopep8 for code formatting.",
    "crumbs": [
      "Data Collection",
      "Scraping Environment"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Market Research",
    "section": "",
    "text": "Welcome to our lecture Market Research (337094a)! üëã\nThis page contains a weekly overview about the topics, slides and materials for the semester.\n\nMoodle-course\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis overview will be updated as the semester progresses.\n\n\n\n\n\nNr\nDate\nContent\nResources\n\n\n\n\n1\n\nIntroduction\n\n\n\n2\n03.04.\nBig Data & Web Analytics\nüìë\n\n\n3\n10.04.\nPrompt Engineering Basics\n\n\n\n4\n\nGenerative AI\n\n\n\n5\n24.04.\nAnaconda environment\n‚öíÔ∏è\n\n\n6\n24.04.\nAssistants API from Open AI\nMoodle\n\n\n7\n24.04.\nChat-Frontend: Streamlit Dashboard\n\n\n\n8\n01.05.\nGenerative AI (01.05 - 07.06.)\nMoodle\n\n\n9\n\nWeb Analytics\n\n\n\n10\n07.06.\nDigital Customer Journey\nüìë\n\n\n11\n07.06.\nWeb tracking mit Blogger\nDemo\n\n\n12\n07.06.\nGoogle Analytics\nüìë\n\n\n13\n07.06.\nUTM Tracking\nüìë\n\n\n14\n07.06.\nFacebook Kennzahlen\nüìë\n\n\n15\n07.06.\nCase Facebook\nüìä\n\n\n16\n07.06.\nCase Facebook Ads Kampagnen\nüìä\n\n\n17\n12.06.\nMerchandise Pivot Case Study\nüìä\n\n\n18\n12.06.\nCase Werbeinventar\nüìä\n\n\n20\n19.06.\nBuyer Personas\nüìù\n\n\n19\n19.06.\nSocial Media Kennzahlen\nüìù\n\n\n20\n19.06.\nSocial Media Template\nüìù\n\n\n21\n19.06.\nSocial Media Tools\nüìë\n\n\n21\n19.06.\nMarketing Tools\nüìë\n\n\n22\n19.06.\nInfluencer\nüìë",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "code/notebook.html",
    "href": "code/notebook.html",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#setup",
    "href": "code/notebook.html#setup",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#data",
    "href": "code/notebook.html#data",
    "title": "Notebook",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "programming-requirements.html",
    "href": "programming-requirements.html",
    "title": "Programming Requirements",
    "section": "",
    "text": "For this course you will need the following setup:\n\nPython: Anaconda, Anaconda Environment mr and Visual Studio Code\n\n\n\n\n\n\n\nImportant\n\n\n\nVisit the ‚ÄúProgramming Toolkit-webpage‚Äù to learn how to meet all requirements.",
    "crumbs": [
      "Data Collection",
      "Requirements"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "If you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures",
    "href": "course-support.html#lectures",
    "title": "Course support",
    "section": "",
    "text": "If you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#discussion-forum",
    "href": "course-support.html#discussion-forum",
    "title": "Course support",
    "section": "Discussion forum",
    "text": "Discussion forum\nPrefer to write out your question in detail rather than asking in person? The online discussion forum is the best venue for these! We will use the Moodle forum as the online discussion forum. There is a chance another student has already asked a similar question, so please check the other posts before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Moodle), and only use email for questions about personal matters that may not be appropriate for the public course forum. For such matters, you may email me at kirenz@hdm-stuttgart.de.\nIf there is a question that‚Äôs not appropriate for the public forum, you are welcome to email me directly. If you email me, please include the name of our course in the subject line.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Center for Learning and Development: it offers free services to all students.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "This course offers a comprehensive overview of data-driven decision-making techniques for business related topics.\nBeginning with the Business Model Canvas, it highlights the importance of data in competitive analysis. Learners will explore study design, including data collection methods and a practical guide on conducting experiments and A/B-tests, essential for strategic decision-making. The curriculum advances through data preparation and analysis, emphasizing competitive market analysis and the transformation of raw data into actionable insights. The course delves into analytical models, covering classification, regression, and cluster analysis for market trend prediction. Participants will also master the usage of Generative AI tools, learning to optimize their work outcomes through effective AI utilization.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "tbd"
  }
]